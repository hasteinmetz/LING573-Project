{
	"lr_transformer": 5e-5,
	"lr_classifier": 8e-3,
	"lr_regressor": 1e-2,
	"batch_size": 24,
	"kfolds": 3,
	"epochs": 3,
	"hidden_size": 40,
	"dropout_mlp": 0.4,
	"dropout_roberta": 0.2
}