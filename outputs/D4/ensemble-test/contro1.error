Using the GPU:Tesla M10
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
	(epoch 1, fold 1, samples 240) FClassifier Loss: 0.7046179622411728 Transformer Loss: 0.703098714351654
	(epoch 1, fold 1, samples 480) FClassifier Loss: 0.6810794944564501 Transformer Loss: 0.6745839715003967
	(epoch 1, fold 1, samples 720) FClassifier Loss: 0.6837620288133621 Transformer Loss: 0.6970017552375793
	(epoch 1, fold 1, samples 960) FClassifier Loss: 0.707578033208847 Transformer Loss: 0.6925337910652161
	(epoch 1, fold 1, samples 1200) FClassifier Loss: 0.694767323633035 Transformer Loss: 0.7261070609092712
	(epoch 1, fold 1, samples 1440) FClassifier Loss: 0.6795362581809361 Transformer Loss: 0.6977486610412598
	(epoch 1, fold 1, samples 1680) FClassifier Loss: 0.681294359266758 Transformer Loss: 0.7000489234924316
	(epoch 1, fold 1, samples 1920) FClassifier Loss: 0.6998527646064758 Transformer Loss: 0.6904497742652893
	(epoch 1, fold 1, samples 2160) FClassifier Loss: 0.6859346826871235 Transformer Loss: 0.6952729821205139
	(epoch 1, fold 1, samples 2400) FClassifier Loss: 0.6947551568349202 Transformer Loss: 0.7005793452262878
	(epoch 1, fold 1, samples 2640) FClassifier Loss: 0.6920697713891665 Transformer Loss: 0.6802597641944885
	(epoch 1, fold 1, samples 2880) FClassifier Loss: 0.6856290176510811 Transformer Loss: 0.6916770339012146
	(epoch 1, fold 1, samples 3120) FClassifier Loss: 0.7026316051681836 Transformer Loss: 0.6561740040779114
(epoch 1, fold 1, samples 240) Regression Accuracy: 0.5, Loss: 0.6966707110404968
(epoch 1, fold 1, samples 480) Regression Accuracy: 0.6666666666666666, Loss: 0.669105052947998
(epoch 1, fold 1, samples 720) Regression Accuracy: 0.4166666666666667, Loss: 0.7101078033447266
	(epoch 1, fold 2, samples 240) FClassifier Loss: 0.6914489914973576 Transformer Loss: 0.6784281134605408
	(epoch 1, fold 2, samples 480) FClassifier Loss: 0.6915909796953201 Transformer Loss: 0.6787973046302795
	(epoch 1, fold 2, samples 720) FClassifier Loss: 0.6951172823707262 Transformer Loss: 0.6927163004875183
	(epoch 1, fold 2, samples 960) FClassifier Loss: 0.6918932795524597 Transformer Loss: 0.7514724731445312
	(epoch 1, fold 2, samples 1200) FClassifier Loss: 0.6965782369176546 Transformer Loss: 0.6895322203636169
	(epoch 1, fold 2, samples 1440) FClassifier Loss: 0.6956001122792561 Transformer Loss: 0.7200495600700378
	(epoch 1, fold 2, samples 1680) FClassifier Loss: 0.6858676448464394 Transformer Loss: 0.6983163356781006
	(epoch 1, fold 2, samples 1920) FClassifier Loss: 0.6856607223550478 Transformer Loss: 0.7033402919769287
	(epoch 1, fold 2, samples 2160) FClassifier Loss: 0.6946805939078331 Transformer Loss: 0.6970072388648987
	(epoch 1, fold 2, samples 2400) FClassifier Loss: 0.68855948249499 Transformer Loss: 0.6977195143699646
	(epoch 1, fold 2, samples 2640) FClassifier Loss: 0.6719381113847096 Transformer Loss: 0.6642381548881531
	(epoch 1, fold 2, samples 2880) FClassifier Loss: 0.6632573803265889 Transformer Loss: 0.6888628602027893
	(epoch 1, fold 2, samples 3120) FClassifier Loss: 0.7051549231012662 Transformer Loss: 0.677886426448822
(epoch 1, fold 2, samples 240) Regression Accuracy: 0.4583333333333333, Loss: 0.7056831121444702
(epoch 1, fold 2, samples 480) Regression Accuracy: 0.625, Loss: 0.6739063262939453
(epoch 1, fold 2, samples 720) Regression Accuracy: 0.5833333333333334, Loss: 0.681861400604248
	(epoch 1, fold 3, samples 240) FClassifier Loss: 0.679996483027935 Transformer Loss: 0.684700071811676
	(epoch 1, fold 3, samples 480) FClassifier Loss: 0.7076238443454106 Transformer Loss: 0.7263414263725281
	(epoch 1, fold 3, samples 720) FClassifier Loss: 0.699494903286298 Transformer Loss: 0.7100734710693359
	(epoch 1, fold 3, samples 960) FClassifier Loss: 0.664950596789519 Transformer Loss: 0.6785839200019836
	(epoch 1, fold 3, samples 1200) FClassifier Loss: 0.6862124850352604 Transformer Loss: 0.6808984279632568
	(epoch 1, fold 3, samples 1440) FClassifier Loss: 0.6814281021555264 Transformer Loss: 0.6910815238952637
	(epoch 1, fold 3, samples 1680) FClassifier Loss: 0.6680561949809392 Transformer Loss: 0.7144834995269775
	(epoch 1, fold 3, samples 1920) FClassifier Loss: 0.7050093114376068 Transformer Loss: 0.6869288086891174
	(epoch 1, fold 3, samples 2160) FClassifier Loss: 0.6812176058689753 Transformer Loss: 0.6922906041145325
	(epoch 1, fold 3, samples 2400) FClassifier Loss: 0.6836847538749377 Transformer Loss: 0.7014718651771545
	(epoch 1, fold 3, samples 2640) FClassifier Loss: 0.6757061307628949 Transformer Loss: 0.6739382743835449
	(epoch 1, fold 3, samples 2880) FClassifier Loss: 0.6719948351383209 Transformer Loss: 0.6849455237388611
	(epoch 1, fold 3, samples 3120) FClassifier Loss: 0.6912313575545946 Transformer Loss: 0.6905124187469482
(epoch 1, fold 3, samples 240) Regression Accuracy: 0.4583333333333333, Loss: 0.7042571306228638
(epoch 1, fold 3, samples 480) Regression Accuracy: 0.5833333333333334, Loss: 0.6817940473556519
(epoch 1, fold 3, samples 720) Regression Accuracy: 0.4583333333333333, Loss: 0.7037429809570312
	(epoch 1, fold 4, samples 240) FClassifier Loss: 0.672672726213932 Transformer Loss: 0.69256591796875
	(epoch 1, fold 4, samples 480) FClassifier Loss: 0.6654191687703133 Transformer Loss: 0.7299232482910156
	(epoch 1, fold 4, samples 720) FClassifier Loss: 0.6638561338186264 Transformer Loss: 0.6973121762275696
	(epoch 1, fold 4, samples 960) FClassifier Loss: 0.6922033901015917 Transformer Loss: 0.6742745041847229
	(epoch 1, fold 4, samples 1200) FClassifier Loss: 0.6873715594410896 Transformer Loss: 0.6730354428291321
	(epoch 1, fold 4, samples 1440) FClassifier Loss: 0.6801325629154841 Transformer Loss: 0.6901161670684814
	(epoch 1, fold 4, samples 1680) FClassifier Loss: 0.6440613890687624 Transformer Loss: 0.6862193942070007
	(epoch 1, fold 4, samples 1920) FClassifier Loss: 0.646397237976392 Transformer Loss: 0.7031612992286682
	(epoch 1, fold 4, samples 2160) FClassifier Loss: 0.6920029371976852 Transformer Loss: 0.6930070519447327
	(epoch 1, fold 4, samples 2400) FClassifier Loss: 0.6871269568800926 Transformer Loss: 0.7017766833305359
	(epoch 1, fold 4, samples 2640) FClassifier Loss: 0.637375966956218 Transformer Loss: 0.664201021194458
	(epoch 1, fold 4, samples 2880) FClassifier Loss: 0.6917939657966296 Transformer Loss: 0.6981229782104492
	(epoch 1, fold 4, samples 3120) FClassifier Loss: 0.6786056334773699 Transformer Loss: 0.6896241307258606
(epoch 1, fold 4, samples 240) Regression Accuracy: 0.375, Loss: 0.7084046602249146
(epoch 1, fold 4, samples 480) Regression Accuracy: 0.25, Loss: 0.7249769568443298
(epoch 1, fold 4, samples 720) Regression Accuracy: 0.4166666666666667, Loss: 0.7027840614318848
	(epoch 1, fold 5, samples 240) FClassifier Loss: 0.6294909218947092 Transformer Loss: 0.6953389048576355
	(epoch 1, fold 5, samples 480) FClassifier Loss: 0.6448875951270262 Transformer Loss: 0.727384090423584
	(epoch 1, fold 5, samples 720) FClassifier Loss: 0.6389484591782093 Transformer Loss: 0.7241425514221191
	(epoch 1, fold 5, samples 960) FClassifier Loss: 0.6140559936563174 Transformer Loss: 0.6889955997467041
	(epoch 1, fold 5, samples 1200) FClassifier Loss: 0.5974395610392094 Transformer Loss: 0.6942940354347229
	(epoch 1, fold 5, samples 1440) FClassifier Loss: 0.6591463014483452 Transformer Loss: 0.6825858950614929
	(epoch 1, fold 5, samples 1680) FClassifier Loss: 0.6447141654789448 Transformer Loss: 0.6921177506446838
	(epoch 1, fold 5, samples 1920) FClassifier Loss: 0.6602890926102797 Transformer Loss: 0.6964074969291687
	(epoch 1, fold 5, samples 2160) FClassifier Loss: 0.676412413517634 Transformer Loss: 0.6943253874778748
	(epoch 1, fold 5, samples 2400) FClassifier Loss: 0.6382401498655478 Transformer Loss: 0.6978843808174133
	(epoch 1, fold 5, samples 2640) FClassifier Loss: 0.6012536101043224 Transformer Loss: 0.6903796792030334
	(epoch 1, fold 5, samples 2880) FClassifier Loss: 0.5836905166506767 Transformer Loss: 0.7040832042694092
	(epoch 1, fold 5, samples 3120) FClassifier Loss: 0.6455887543658415 Transformer Loss: 0.6907264590263367
(epoch 1, fold 5, samples 240) Regression Accuracy: 0.6666666666666666, Loss: 0.6574140787124634
(epoch 1, fold 5, samples 480) Regression Accuracy: 0.5833333333333334, Loss: 0.6777440309524536
(epoch 1, fold 5, samples 720) Regression Accuracy: 0.6666666666666666, Loss: 0.6557875871658325
