Using the GPU:Tesla M10
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
	(epoch 1, fold 1, samples 320) FClassifier Loss: 0.6795002035796642 Transformer Loss: 0.6683010458946228
	(epoch 1, fold 1, samples 640) FClassifier Loss: 0.6755168437957764 Transformer Loss: 0.5109185576438904
	(epoch 1, fold 1, samples 960) FClassifier Loss: 0.7044994523748755 Transformer Loss: 0.45910391211509705
	(epoch 1, fold 1, samples 1280) FClassifier Loss: 0.6660441821441054 Transformer Loss: 0.5752648115158081
	(epoch 1, fold 1, samples 1600) FClassifier Loss: 0.6683243755251169 Transformer Loss: 0.3485523462295532
	(epoch 1, fold 1, samples 1920) FClassifier Loss: 0.6549647757783532 Transformer Loss: 0.2626989483833313
	(epoch 1, fold 1, samples 2240) FClassifier Loss: 0.6006718073040247 Transformer Loss: 0.1824730783700943
	(epoch 1, fold 1, samples 2560) FClassifier Loss: 0.55101662222296 Transformer Loss: 0.1650102585554123
	(epoch 1, fold 1, samples 2880) FClassifier Loss: 0.5908837504684925 Transformer Loss: 0.10357017070055008
	(epoch 1, fold 1, samples 3200) FClassifier Loss: 0.7032720008864999 Transformer Loss: 0.42079201340675354
	(epoch 1, fold 1, samples 3520) FClassifier Loss: 0.64096456207335 Transformer Loss: 0.39343011379241943
	(epoch 1, fold 1, samples 3840) FClassifier Loss: 0.6839152779430151 Transformer Loss: 0.14243382215499878
	(epoch 1, fold 1, samples 4160) FClassifier Loss: 0.6758202454075217 Transformer Loss: 0.09104151278734207
	(epoch 1, fold 1, samples 4480) FClassifier Loss: 0.6120813246816397 Transformer Loss: 0.3990562856197357
	(epoch 1, fold 1, samples 4800) FClassifier Loss: 0.5978678856045008 Transformer Loss: 0.18546204268932343
	(epoch 1, fold 1, samples 5120) FClassifier Loss: 0.5662432913818667 Transformer Loss: 0.226337268948555
(epoch 1, fold 1, samples 640) Regression Accuracy: 0.96875, Loss: 0.28112906217575073
(epoch 1, fold 1, samples 1280) Regression Accuracy: 0.96875, Loss: 0.2854689359664917
Fold 0 accuracies:
Ensemble	f1: {'f1': 0.9374358974358974}
Ensemble	accuracy: {'accuracy': 0.92375}

Transformer	f1: {'f1': 0.9409409409409408}
Transformer	accuracy: {'accuracy': 0.92625}

Featurizer	f1: {'f1': 0.791599353796446}
Featurizer	accuracy: {'accuracy': 0.6775}

	(epoch 1, fold 2, samples 320) FClassifier Loss: 0.5453389163594693 Transformer Loss: 0.18409089744091034
	(epoch 1, fold 2, samples 640) FClassifier Loss: 0.5038433257432189 Transformer Loss: 0.08946480602025986
	(epoch 1, fold 2, samples 960) FClassifier Loss: 0.4328810418955982 Transformer Loss: 0.22233684360980988
	(epoch 1, fold 2, samples 1280) FClassifier Loss: 0.4524332992732525 Transformer Loss: 0.13152432441711426
	(epoch 1, fold 2, samples 1600) FClassifier Loss: 0.43920277967117727 Transformer Loss: 0.020982103422284126
	(epoch 1, fold 2, samples 1920) FClassifier Loss: 0.4444325426593423 Transformer Loss: 0.06615288555622101
	(epoch 1, fold 2, samples 2240) FClassifier Loss: 0.42778707307297736 Transformer Loss: 0.05976341664791107
	(epoch 1, fold 2, samples 2560) FClassifier Loss: 0.3701559781911783 Transformer Loss: 0.06692782044410706
	(epoch 1, fold 2, samples 2880) FClassifier Loss: 0.38742103381082416 Transformer Loss: 0.01286404114216566
	(epoch 1, fold 2, samples 3200) FClassifier Loss: 0.460049200366484 Transformer Loss: 0.13463695347309113
	(epoch 1, fold 2, samples 3520) FClassifier Loss: 0.37229905327239976 Transformer Loss: 0.2911539673805237
	(epoch 1, fold 2, samples 3840) FClassifier Loss: 0.49048113209573785 Transformer Loss: 0.06058913469314575
	(epoch 1, fold 2, samples 4160) FClassifier Loss: 0.5029285122727742 Transformer Loss: 0.07236777245998383
	(epoch 1, fold 2, samples 4480) FClassifier Loss: 0.45909227075753734 Transformer Loss: 0.1815904974937439
	(epoch 1, fold 2, samples 4800) FClassifier Loss: 0.35768814175389707 Transformer Loss: 0.0802106186747551
	(epoch 1, fold 2, samples 5120) FClassifier Loss: 0.27467623866734003 Transformer Loss: 0.12900875508785248
(epoch 1, fold 2, samples 640) Regression Accuracy: 0.96875, Loss: 0.1480504721403122
(epoch 1, fold 2, samples 1280) Regression Accuracy: 0.9375, Loss: 0.21944108605384827
Fold 1 accuracies:
Ensemble	f1: {'f1': 0.9333333333333332}
Ensemble	accuracy: {'accuracy': 0.92}

Transformer	f1: {'f1': 0.9391124871001032}
Transformer	accuracy: {'accuracy': 0.92625}

Featurizer	f1: {'f1': 0.8415937803692906}
Featurizer	accuracy: {'accuracy': 0.79625}

	(epoch 1, fold 3, samples 320) FClassifier Loss: 0.27689077128161443 Transformer Loss: 0.2633744180202484
	(epoch 1, fold 3, samples 640) FClassifier Loss: 0.2383642280674394 Transformer Loss: 0.010779289528727531
	(epoch 1, fold 3, samples 960) FClassifier Loss: 0.23004132049391046 Transformer Loss: 0.07555441558361053
	(epoch 1, fold 3, samples 1280) FClassifier Loss: 0.3199238278903067 Transformer Loss: 0.17758317291736603
	(epoch 1, fold 3, samples 1600) FClassifier Loss: 0.2184507993515581 Transformer Loss: 0.08838770538568497
	(epoch 1, fold 3, samples 1920) FClassifier Loss: 0.4437969449936645 Transformer Loss: 0.155940979719162
	(epoch 1, fold 3, samples 2240) FClassifier Loss: 0.42747077183867077 Transformer Loss: 0.07370644062757492
	(epoch 1, fold 3, samples 2560) FClassifier Loss: 0.310963325558987 Transformer Loss: 0.19667038321495056
	(epoch 1, fold 3, samples 2880) FClassifier Loss: 0.2525415845225325 Transformer Loss: 0.021830694749951363
	(epoch 1, fold 3, samples 3200) FClassifier Loss: 0.2737551439422532 Transformer Loss: 0.1897186040878296
	(epoch 1, fold 3, samples 3520) FClassifier Loss: 0.21032167489101994 Transformer Loss: 0.17480476200580597
	(epoch 1, fold 3, samples 3840) FClassifier Loss: 0.5996290056773432 Transformer Loss: 0.13316762447357178
	(epoch 1, fold 3, samples 4160) FClassifier Loss: 0.6136276887045824 Transformer Loss: 0.023932715877890587
	(epoch 1, fold 3, samples 4480) FClassifier Loss: 0.3599315894780375 Transformer Loss: 0.128414586186409
	(epoch 1, fold 3, samples 4800) FClassifier Loss: 0.23085608905239496 Transformer Loss: 0.13925309479236603
	(epoch 1, fold 3, samples 5120) FClassifier Loss: 0.17539789837094083 Transformer Loss: 0.018219970166683197
(epoch 1, fold 3, samples 640) Regression Accuracy: 1.0, Loss: 0.044227808713912964
(epoch 1, fold 3, samples 1280) Regression Accuracy: 0.96875, Loss: 0.06629619002342224
Fold 2 accuracies:
Ensemble	f1: {'f1': 0.9511465603190429}
Ensemble	accuracy: {'accuracy': 0.93875}

Transformer	f1: {'f1': 0.9464285714285714}
Transformer	accuracy: {'accuracy': 0.9325}

Featurizer	f1: {'f1': 0.8493150684931506}
Featurizer	accuracy: {'accuracy': 0.8075}

	(epoch 1, fold 4, samples 320) FClassifier Loss: 0.15013590676971944 Transformer Loss: 0.06178538128733635
	(epoch 1, fold 4, samples 640) FClassifier Loss: 0.16047564444977525 Transformer Loss: 0.016670476645231247
	(epoch 1, fold 4, samples 960) FClassifier Loss: 0.11934359528822824 Transformer Loss: 0.041306886821985245
	(epoch 1, fold 4, samples 1280) FClassifier Loss: 0.2791566505366063 Transformer Loss: 0.015045879408717155
	(epoch 1, fold 4, samples 1600) FClassifier Loss: 0.14959685097528563 Transformer Loss: 0.04994147643446922
	(epoch 1, fold 4, samples 1920) FClassifier Loss: 0.3414187829130242 Transformer Loss: 0.10184022039175034
	(epoch 1, fold 4, samples 2240) FClassifier Loss: 0.4010712091367168 Transformer Loss: 0.1306893229484558
	(epoch 1, fold 4, samples 2560) FClassifier Loss: 0.3039914055116242 Transformer Loss: 0.39919236302375793
	(epoch 1, fold 4, samples 2880) FClassifier Loss: 0.17367308581015095 Transformer Loss: 0.14685939252376556
	(epoch 1, fold 4, samples 3200) FClassifier Loss: 0.17742137120148982 Transformer Loss: 0.013387197628617287
	(epoch 1, fold 4, samples 3520) FClassifier Loss: 0.27714647618631716 Transformer Loss: 0.06784871220588684
	(epoch 1, fold 4, samples 3840) FClassifier Loss: 0.17783456192046287 Transformer Loss: 0.08967667073011398
	(epoch 1, fold 4, samples 4160) FClassifier Loss: 0.3684411024514702 Transformer Loss: 0.014424915425479412
	(epoch 1, fold 4, samples 4480) FClassifier Loss: 0.3057751259257202 Transformer Loss: 0.008131112903356552
	(epoch 1, fold 4, samples 4800) FClassifier Loss: 0.14213684124842985 Transformer Loss: 0.0020931954495608807
	(epoch 1, fold 4, samples 5120) FClassifier Loss: 0.15025278370857478 Transformer Loss: 0.008146541193127632
(epoch 1, fold 4, samples 640) Regression Accuracy: 1.0, Loss: 0.07217921316623688
(epoch 1, fold 4, samples 1280) Regression Accuracy: 1.0, Loss: 0.05035320669412613
Fold 3 accuracies:
Ensemble	f1: {'f1': 0.9288461538461538}
Ensemble	accuracy: {'accuracy': 0.9075}

Transformer	f1: {'f1': 0.9279538904899136}
Transformer	accuracy: {'accuracy': 0.90625}

Featurizer	f1: {'f1': 0.8543307086614172}
Featurizer	accuracy: {'accuracy': 0.815}

	(epoch 1, fold 5, samples 320) FClassifier Loss: 0.08513066889281617 Transformer Loss: 0.028538299724459648
	(epoch 1, fold 5, samples 640) FClassifier Loss: 0.08727796172422586 Transformer Loss: 0.036234546452760696
	(epoch 1, fold 5, samples 960) FClassifier Loss: 0.05862053579765458 Transformer Loss: 0.06260812282562256
	(epoch 1, fold 5, samples 1280) FClassifier Loss: 0.18439251163727022 Transformer Loss: 0.11338771879673004
	(epoch 1, fold 5, samples 1600) FClassifier Loss: 0.08962918632664696 Transformer Loss: 0.0023637276608496904
	(epoch 1, fold 5, samples 1920) FClassifier Loss: 0.18756172320945552 Transformer Loss: 0.011705677956342697
	(epoch 1, fold 5, samples 2240) FClassifier Loss: 0.26699094907985454 Transformer Loss: 0.047003887593746185
	(epoch 1, fold 5, samples 2560) FClassifier Loss: 0.25756578944128705 Transformer Loss: 0.4125303030014038
	(epoch 1, fold 5, samples 2880) FClassifier Loss: 0.1080692760515376 Transformer Loss: 0.010720119811594486
	(epoch 1, fold 5, samples 3200) FClassifier Loss: 0.2106151411301198 Transformer Loss: 0.02371666394174099
	(epoch 1, fold 5, samples 3520) FClassifier Loss: 0.18042539679731817 Transformer Loss: 0.03767303004860878
	(epoch 1, fold 5, samples 3840) FClassifier Loss: 0.08501226641419635 Transformer Loss: 0.027182135730981827
	(epoch 1, fold 5, samples 4160) FClassifier Loss: 0.2150294529022858 Transformer Loss: 0.09720596671104431
	(epoch 1, fold 5, samples 4480) FClassifier Loss: 0.18887758992403292 Transformer Loss: 0.019547929987311363
	(epoch 1, fold 5, samples 4800) FClassifier Loss: 0.16740891708286654 Transformer Loss: 0.07002457231283188
	(epoch 1, fold 5, samples 5120) FClassifier Loss: 0.3234826649872957 Transformer Loss: 0.08641367405653
(epoch 1, fold 5, samples 640) Regression Accuracy: 1.0, Loss: 0.03737327456474304
(epoch 1, fold 5, samples 1280) Regression Accuracy: 0.967741935483871, Loss: 0.060190729796886444
Fold 4 accuracies:
Ensemble	f1: {'f1': 0.9348500517063082}
Ensemble	accuracy: {'accuracy': 0.92125}

Transformer	f1: {'f1': 0.9344262295081968}
Transformer	accuracy: {'accuracy': 0.92}

Featurizer	f1: {'f1': 0.851445663010967}
Featurizer	accuracy: {'accuracy': 0.81375}

Epoch 0 accuracies:
Ensemble	f1: {'f1': 0.9348500517063082}
Ensemble	accuracy: {'accuracy': 0.92125}

Transformer	f1: {'f1': 0.9344262295081968}
Transformer	accuracy: {'accuracy': 0.92}

Featurizer	f1: {'f1': 0.851445663010967}
Featurizer	accuracy: {'accuracy': 0.81375}

