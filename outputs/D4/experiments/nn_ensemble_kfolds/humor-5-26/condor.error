Using the GPU:NVIDIA Quadro RTX 8000
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
	(epoch 1, fold 1, samples 320) FClassifier Loss: 0.6855812910944223 Transformer Loss: 0.6743635637685657
	(epoch 1, fold 1, samples 640) FClassifier Loss: 0.6565543143078685 Transformer Loss: 0.5113357028458267
	(epoch 1, fold 1, samples 960) FClassifier Loss: 0.6973875081166625 Transformer Loss: 0.6311866065952927
	(epoch 1, fold 1, samples 1280) FClassifier Loss: 0.6485753627493978 Transformer Loss: 0.4978222654899582
	(epoch 1, fold 1, samples 1600) FClassifier Loss: 0.6630796734243631 Transformer Loss: 0.5925086100469343
	(epoch 1, fold 1, samples 1920) FClassifier Loss: 0.6583508374169469 Transformer Loss: 0.24464683886617422
	(epoch 1, fold 1, samples 2240) FClassifier Loss: 0.6085210470482707 Transformer Loss: 0.14171710336813703
	(epoch 1, fold 1, samples 2560) FClassifier Loss: 0.553540023509413 Transformer Loss: 0.09645689859462436
	(epoch 1, fold 1, samples 2880) FClassifier Loss: 0.598030615132302 Transformer Loss: 0.32788811207865365
	(epoch 1, fold 1, samples 3200) FClassifier Loss: 0.6952466303482652 Transformer Loss: 0.3181663792929612
	(epoch 1, fold 1, samples 3520) FClassifier Loss: 0.5996782570146024 Transformer Loss: 0.28343739798583556
	(epoch 1, fold 1, samples 3840) FClassifier Loss: 0.6758052362129092 Transformer Loss: 0.3700297424365999
	(epoch 1, fold 1, samples 4160) FClassifier Loss: 0.7273381226696074 Transformer Loss: 0.16885552283201832
	(epoch 1, fold 1, samples 4480) FClassifier Loss: 0.5645906487479806 Transformer Loss: 0.35045157268905314
	(epoch 1, fold 1, samples 4800) FClassifier Loss: 0.6147102685645223 Transformer Loss: 0.293713110324461
	(epoch 1, fold 1, samples 5120) FClassifier Loss: 0.4857490716441985 Transformer Loss: 0.30622823799269333
(epoch 1, fold 1, samples 640) Regression Accuracy: 1.0, Loss: 0.27934467792510986
(epoch 1, fold 1, samples 1280) Regression Accuracy: 0.9375, Loss: 0.25602421164512634
Fold 0 accuracies:
Ensemble	f1: {'f1': 0.9320987654320988}
Ensemble	accuracy: {'accuracy': 0.9175}

Transformer	f1: {'f1': 0.9378185524974516}
Transformer	accuracy: {'accuracy': 0.92375}

Featurizer	f1: {'f1': 0.8139130434782609}
Featurizer	accuracy: {'accuracy': 0.7325}

	(epoch 1, fold 2, samples 320) FClassifier Loss: 0.4924382133758627 Transformer Loss: 0.10827457984123612
	(epoch 1, fold 2, samples 640) FClassifier Loss: 0.5272142478497699 Transformer Loss: 0.03830660095991334
	(epoch 1, fold 2, samples 960) FClassifier Loss: 0.47969712037593126 Transformer Loss: 0.18276101355877472
	(epoch 1, fold 2, samples 1280) FClassifier Loss: 0.4443235801300034 Transformer Loss: 0.23059564494906226
	(epoch 1, fold 2, samples 1600) FClassifier Loss: 0.35135448281653225 Transformer Loss: 0.23493046207659063
	(epoch 1, fold 2, samples 1920) FClassifier Loss: 0.37452763493638486 Transformer Loss: 0.047485323128057644
	(epoch 1, fold 2, samples 2240) FClassifier Loss: 0.3498188863886753 Transformer Loss: 0.07485734204965411
	(epoch 1, fold 2, samples 2560) FClassifier Loss: 0.3197420772485202 Transformer Loss: 0.014863557189528365
	(epoch 1, fold 2, samples 2880) FClassifier Loss: 0.4579528352187481 Transformer Loss: 0.04228763488936238
	(epoch 1, fold 2, samples 3200) FClassifier Loss: 0.38778345756145427 Transformer Loss: 0.3124230442917906
	(epoch 1, fold 2, samples 3520) FClassifier Loss: 0.36321848642546684 Transformer Loss: 0.22424747742479667
	(epoch 1, fold 2, samples 3840) FClassifier Loss: 0.533686492650304 Transformer Loss: 0.06733551002980676
	(epoch 1, fold 2, samples 4160) FClassifier Loss: 0.6108019532402977 Transformer Loss: 0.021611734311591135
	(epoch 1, fold 2, samples 4480) FClassifier Loss: 0.638145990727935 Transformer Loss: 0.3531285680073779
	(epoch 1, fold 2, samples 4800) FClassifier Loss: 0.30262878771463875 Transformer Loss: 0.08529115078636096
	(epoch 1, fold 2, samples 5120) FClassifier Loss: 0.26798774419172156 Transformer Loss: 0.051034813671703295
(epoch 1, fold 2, samples 640) Regression Accuracy: 0.96875, Loss: 0.11468050628900528
(epoch 1, fold 2, samples 1280) Regression Accuracy: 0.875, Loss: 0.2682514786720276
Fold 1 accuracies:
Ensemble	f1: {'f1': 0.9311408016443988}
Ensemble	accuracy: {'accuracy': 0.91625}

Transformer	f1: {'f1': 0.9304703476482618}
Transformer	accuracy: {'accuracy': 0.915}

Featurizer	f1: {'f1': 0.8477611940298507}
Featurizer	accuracy: {'accuracy': 0.80875}

	(epoch 1, fold 3, samples 320) FClassifier Loss: 0.27272479387465864 Transformer Loss: 0.011729859535989817
	(epoch 1, fold 3, samples 640) FClassifier Loss: 0.20988840177142265 Transformer Loss: 0.08470330860291142
	(epoch 1, fold 3, samples 960) FClassifier Loss: 0.25450859166448936 Transformer Loss: 0.11618284382711863
	(epoch 1, fold 3, samples 1280) FClassifier Loss: 0.31714482349707396 Transformer Loss: 0.18054357641449315
	(epoch 1, fold 3, samples 1600) FClassifier Loss: 0.23901894077425823 Transformer Loss: 0.2116654717901838
	(epoch 1, fold 3, samples 1920) FClassifier Loss: 0.4016878811235074 Transformer Loss: 0.09376939153298736
	(epoch 1, fold 3, samples 2240) FClassifier Loss: 0.5829763683650526 Transformer Loss: 0.06159047672554152
	(epoch 1, fold 3, samples 2560) FClassifier Loss: 0.3838838470255723 Transformer Loss: 0.37776910188404145
	(epoch 1, fold 3, samples 2880) FClassifier Loss: 0.30090409256808925 Transformer Loss: 0.13153595774201676
	(epoch 1, fold 3, samples 3200) FClassifier Loss: 0.30393781080056215 Transformer Loss: 0.30055990317850956
	(epoch 1, fold 3, samples 3520) FClassifier Loss: 0.27916100864058535 Transformer Loss: 0.10778888990171254
	(epoch 1, fold 3, samples 3840) FClassifier Loss: 0.44604363809048664 Transformer Loss: 0.07928951924623107
	(epoch 1, fold 3, samples 4160) FClassifier Loss: 0.40527808864135295 Transformer Loss: 0.04019440995762125
	(epoch 1, fold 3, samples 4480) FClassifier Loss: 0.39284304168540984 Transformer Loss: 0.0038099049306765664
	(epoch 1, fold 3, samples 4800) FClassifier Loss: 0.17747309181140736 Transformer Loss: 0.04935220432707865
	(epoch 1, fold 3, samples 5120) FClassifier Loss: 0.20694672093997077 Transformer Loss: 0.07063241055866162
(epoch 1, fold 3, samples 640) Regression Accuracy: 1.0, Loss: 0.037978511303663254
(epoch 1, fold 3, samples 1280) Regression Accuracy: 0.96875, Loss: 0.06664655357599258
Fold 2 accuracies:
Ensemble	f1: {'f1': 0.939571150097466}
Ensemble	accuracy: {'accuracy': 0.9225}

Transformer	f1: {'f1': 0.9357976653696498}
Transformer	accuracy: {'accuracy': 0.9175}

Featurizer	f1: {'f1': 0.8525896414342629}
Featurizer	accuracy: {'accuracy': 0.815}

	(epoch 1, fold 4, samples 320) FClassifier Loss: 0.12287779982580105 Transformer Loss: 0.043929424149609986
	(epoch 1, fold 4, samples 640) FClassifier Loss: 0.12365667907351963 Transformer Loss: 0.00946045543969376
	(epoch 1, fold 4, samples 960) FClassifier Loss: 0.16633435522817308 Transformer Loss: 0.006361450346958009
	(epoch 1, fold 4, samples 1280) FClassifier Loss: 0.21904558338792413 Transformer Loss: 0.20409820812528778
	(epoch 1, fold 4, samples 1600) FClassifier Loss: 0.17006703220613417 Transformer Loss: 0.009798915087230853
	(epoch 1, fold 4, samples 1920) FClassifier Loss: 0.2434079627855681 Transformer Loss: 0.0428110101402126
	(epoch 1, fold 4, samples 2240) FClassifier Loss: 0.2559320995678718 Transformer Loss: 0.06583470962505089
	(epoch 1, fold 4, samples 2560) FClassifier Loss: 0.30755367193816596 Transformer Loss: 0.16534534070706286
	(epoch 1, fold 4, samples 2880) FClassifier Loss: 0.1939053351588882 Transformer Loss: 0.012239100975421024
	(epoch 1, fold 4, samples 3200) FClassifier Loss: 0.21889704821660416 Transformer Loss: 0.0340602240703447
	(epoch 1, fold 4, samples 3520) FClassifier Loss: 0.2933909179045955 Transformer Loss: 0.025198084371368168
	(epoch 1, fold 4, samples 3840) FClassifier Loss: 0.1534079049488355 Transformer Loss: 0.1021711807243264
	(epoch 1, fold 4, samples 4160) FClassifier Loss: 0.4376770475428202 Transformer Loss: 0.044056577135052066
	(epoch 1, fold 4, samples 4480) FClassifier Loss: 0.42348037426927476 Transformer Loss: 0.09667520040966338
	(epoch 1, fold 4, samples 4800) FClassifier Loss: 0.1603806621669719 Transformer Loss: 0.018070418811475975
	(epoch 1, fold 4, samples 5120) FClassifier Loss: 0.1419302350766356 Transformer Loss: 0.006021303644839434
(epoch 1, fold 4, samples 640) Regression Accuracy: 0.9375, Loss: 0.12938088178634644
(epoch 1, fold 4, samples 1280) Regression Accuracy: 1.0, Loss: 0.011791393160820007
Fold 3 accuracies:
Ensemble	f1: {'f1': 0.9409326424870467}
Ensemble	accuracy: {'accuracy': 0.92875}

Transformer	f1: {'f1': 0.9432404540763674}
Transformer	accuracy: {'accuracy': 0.93125}

Featurizer	f1: {'f1': 0.849150849150849}
Featurizer	accuracy: {'accuracy': 0.81125}

	(epoch 1, fold 5, samples 320) FClassifier Loss: 0.11166606419055825 Transformer Loss: 0.0027116095789097017
	(epoch 1, fold 5, samples 640) FClassifier Loss: 0.08384065229643056 Transformer Loss: 0.0017219158489751862
	(epoch 1, fold 5, samples 960) FClassifier Loss: 0.1531273572200007 Transformer Loss: 0.0027417318160587456
	(epoch 1, fold 5, samples 1280) FClassifier Loss: 0.24085228623971489 Transformer Loss: 0.002567571189501905
	(epoch 1, fold 5, samples 1600) FClassifier Loss: 0.07926296368276553 Transformer Loss: 0.013514775562725845
	(epoch 1, fold 5, samples 1920) FClassifier Loss: 0.3014162875610964 Transformer Loss: 0.026059226875077002
	(epoch 1, fold 5, samples 2240) FClassifier Loss: 0.2923538187614838 Transformer Loss: 0.2874756370565592
	(epoch 1, fold 5, samples 2560) FClassifier Loss: 0.33141859591705725 Transformer Loss: 0.043068350805697264
	(epoch 1, fold 5, samples 2880) FClassifier Loss: 0.0867625851315097 Transformer Loss: 0.014839729103186983
	(epoch 1, fold 5, samples 3200) FClassifier Loss: 0.19162068341574923 Transformer Loss: 0.0021843446484126616
	(epoch 1, fold 5, samples 3520) FClassifier Loss: 0.26792566478741264 Transformer Loss: 0.010662151045835344
	(epoch 1, fold 5, samples 3840) FClassifier Loss: 0.09278267778427107 Transformer Loss: 0.01300182696650154
	(epoch 1, fold 5, samples 4160) FClassifier Loss: 0.2409461925708456 Transformer Loss: 0.004667806439101696
	(epoch 1, fold 5, samples 4480) FClassifier Loss: 0.24981928167835576 Transformer Loss: 0.08225220023632573
	(epoch 1, fold 5, samples 4800) FClassifier Loss: 0.18281595461047573 Transformer Loss: 0.07100968772374472
	(epoch 1, fold 5, samples 5120) FClassifier Loss: 0.5579228625365431 Transformer Loss: 0.006017718520524795
(epoch 1, fold 5, samples 640) Regression Accuracy: 1.0, Loss: 0.010310666635632515
(epoch 1, fold 5, samples 1280) Regression Accuracy: 0.967741935483871, Loss: 0.034930337220430374
Fold 4 accuracies:
Ensemble	f1: {'f1': 0.9396378269617706}
Ensemble	accuracy: {'accuracy': 0.925}

Transformer	f1: {'f1': 0.9398797595190381}
Transformer	accuracy: {'accuracy': 0.925}

Featurizer	f1: {'f1': 0.8496993987975952}
Featurizer	accuracy: {'accuracy': 0.8125}

Epoch 0 accuracies:
Ensemble	f1: {'f1': 0.9396378269617706}
Ensemble	accuracy: {'accuracy': 0.925}

Transformer	f1: {'f1': 0.9398797595190381}
Transformer	accuracy: {'accuracy': 0.925}

Featurizer	f1: {'f1': 0.8496993987975952}
Featurizer	accuracy: {'accuracy': 0.8125}


real	90m39.251s
user	84m38.904s
sys	4m31.798s
