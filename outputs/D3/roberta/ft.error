Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
***** Running training *****
  Num examples = 6399
  Num Epochs = 1
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 200
  0%|          | 0/200 [00:00<?, ?it/s]/projects/assigned/2122_ling573_elibales/repo/src/fine-tune.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  item = {key: torch.tensor(val[index]) for key, val in self.encodings.items()}
  0%|          | 1/200 [00:02<09:25,  2.84s/it]  1%|          | 2/200 [00:05<09:04,  2.75s/it]  2%|▏         | 3/200 [00:08<08:56,  2.72s/it]  2%|▏         | 4/200 [00:10<08:51,  2.71s/it]  2%|▎         | 5/200 [00:13<08:47,  2.71s/it]  3%|▎         | 6/200 [00:16<08:44,  2.70s/it]  4%|▎         | 7/200 [00:18<08:40,  2.70s/it]  4%|▍         | 8/200 [00:21<08:37,  2.70s/it]  4%|▍         | 9/200 [00:24<08:34,  2.70s/it]  5%|▌         | 10/200 [00:27<08:32,  2.70s/it]  6%|▌         | 11/200 [00:29<08:29,  2.70s/it]  6%|▌         | 12/200 [00:32<08:26,  2.70s/it]  6%|▋         | 13/200 [00:35<08:24,  2.70s/it]  7%|▋         | 14/200 [00:37<08:21,  2.70s/it]  8%|▊         | 15/200 [00:40<08:19,  2.70s/it]  8%|▊         | 16/200 [00:43<08:16,  2.70s/it]  8%|▊         | 17/200 [00:45<08:14,  2.70s/it]  9%|▉         | 18/200 [00:48<08:11,  2.70s/it] 10%|▉         | 19/200 [00:51<08:08,  2.70s/it] 10%|█         | 20/200 [00:54<08:06,  2.70s/it] 10%|█         | 21/200 [00:56<08:03,  2.70s/it] 11%|█         | 22/200 [00:59<08:00,  2.70s/it] 12%|█▏        | 23/200 [01:02<07:57,  2.70s/it] 12%|█▏        | 24/200 [01:04<07:54,  2.70s/it] 12%|█▎        | 25/200 [01:07<07:52,  2.70s/it] 13%|█▎        | 26/200 [01:10<07:49,  2.70s/it] 14%|█▎        | 27/200 [01:12<07:47,  2.70s/it] 14%|█▍        | 28/200 [01:15<07:44,  2.70s/it] 14%|█▍        | 29/200 [01:18<07:41,  2.70s/it] 15%|█▌        | 30/200 [01:21<07:39,  2.70s/it] 16%|█▌        | 31/200 [01:23<07:36,  2.70s/it] 16%|█▌        | 32/200 [01:26<07:33,  2.70s/it] 16%|█▋        | 33/200 [01:29<07:31,  2.70s/it] 17%|█▋        | 34/200 [01:31<07:28,  2.70s/it] 18%|█▊        | 35/200 [01:34<07:26,  2.70s/it] 18%|█▊        | 36/200 [01:37<07:24,  2.71s/it] 18%|█▊        | 37/200 [01:40<07:22,  2.71s/it] 19%|█▉        | 38/200 [01:42<07:19,  2.71s/it] 20%|█▉        | 39/200 [01:45<07:15,  2.71s/it] 20%|██        | 40/200 [01:48<07:12,  2.71s/it] 20%|██        | 41/200 [01:50<07:09,  2.70s/it] 21%|██        | 42/200 [01:53<07:07,  2.70s/it] 22%|██▏       | 43/200 [01:56<07:04,  2.70s/it] 22%|██▏       | 44/200 [01:58<07:01,  2.70s/it] 22%|██▎       | 45/200 [02:01<06:58,  2.70s/it] 23%|██▎       | 46/200 [02:04<06:56,  2.70s/it] 24%|██▎       | 47/200 [02:07<06:53,  2.70s/it] 24%|██▍       | 48/200 [02:09<06:50,  2.70s/it] 24%|██▍       | 49/200 [02:12<06:48,  2.70s/it] 25%|██▌       | 50/200 [02:15<06:45,  2.70s/it] 26%|██▌       | 51/200 [02:17<06:42,  2.70s/it] 26%|██▌       | 52/200 [02:20<06:40,  2.71s/it] 26%|██▋       | 53/200 [02:23<06:37,  2.70s/it] 27%|██▋       | 54/200 [02:26<06:34,  2.70s/it] 28%|██▊       | 55/200 [02:28<06:32,  2.70s/it] 28%|██▊       | 56/200 [02:31<06:30,  2.71s/it] 28%|██▊       | 57/200 [02:34<06:27,  2.71s/it] 29%|██▉       | 58/200 [02:36<06:24,  2.71s/it] 30%|██▉       | 59/200 [02:39<06:21,  2.71s/it] 30%|███       | 60/200 [02:42<06:18,  2.70s/it] 30%|███       | 61/200 [02:44<06:15,  2.70s/it] 31%|███       | 62/200 [02:47<06:12,  2.70s/it] 32%|███▏      | 63/200 [02:50<06:10,  2.70s/it] 32%|███▏      | 64/200 [02:53<06:07,  2.70s/it] 32%|███▎      | 65/200 [02:55<06:04,  2.70s/it] 33%|███▎      | 66/200 [02:58<06:02,  2.70s/it] 34%|███▎      | 67/200 [03:01<05:59,  2.71s/it] 34%|███▍      | 68/200 [03:03<05:57,  2.71s/it] 34%|███▍      | 69/200 [03:06<05:54,  2.71s/it] 35%|███▌      | 70/200 [03:09<05:51,  2.70s/it] 36%|███▌      | 71/200 [03:11<05:48,  2.70s/it] 36%|███▌      | 72/200 [03:14<05:46,  2.70s/it] 36%|███▋      | 73/200 [03:17<05:43,  2.70s/it] 37%|███▋      | 74/200 [03:20<05:40,  2.70s/it] 38%|███▊      | 75/200 [03:22<05:37,  2.70s/it] 38%|███▊      | 76/200 [03:25<05:36,  2.71s/it] 38%|███▊      | 77/200 [03:28<05:33,  2.71s/it] 39%|███▉      | 78/200 [03:30<05:30,  2.71s/it] 40%|███▉      | 79/200 [03:33<05:27,  2.71s/it] 40%|████      | 80/200 [03:36<05:24,  2.71s/it] 40%|████      | 81/200 [03:39<05:21,  2.71s/it] 41%|████      | 82/200 [03:41<05:19,  2.71s/it] 42%|████▏     | 83/200 [03:44<05:16,  2.71s/it] 42%|████▏     | 84/200 [03:47<05:14,  2.71s/it] 42%|████▎     | 85/200 [03:49<05:11,  2.71s/it] 43%|████▎     | 86/200 [03:52<05:08,  2.71s/it] 44%|████▎     | 87/200 [03:55<05:05,  2.71s/it] 44%|████▍     | 88/200 [03:57<05:02,  2.71s/it] 44%|████▍     | 89/200 [04:00<05:00,  2.70s/it] 45%|████▌     | 90/200 [04:03<04:57,  2.70s/it] 46%|████▌     | 91/200 [04:06<04:54,  2.70s/it] 46%|████▌     | 92/200 [04:08<04:52,  2.71s/it] 46%|████▋     | 93/200 [04:11<04:49,  2.71s/it] 47%|████▋     | 94/200 [04:14<04:46,  2.71s/it] 48%|████▊     | 95/200 [04:16<04:44,  2.71s/it] 48%|████▊     | 96/200 [04:19<04:42,  2.71s/it] 48%|████▊     | 97/200 [04:22<04:39,  2.71s/it] 49%|████▉     | 98/200 [04:25<04:36,  2.71s/it] 50%|████▉     | 99/200 [04:27<04:33,  2.71s/it] 50%|█████     | 100/200 [04:30<04:30,  2.71s/it] 50%|█████     | 101/200 [04:33<04:27,  2.71s/it] 51%|█████     | 102/200 [04:35<04:25,  2.71s/it] 52%|█████▏    | 103/200 [04:38<04:22,  2.71s/it] 52%|█████▏    | 104/200 [04:41<04:19,  2.71s/it] 52%|█████▎    | 105/200 [04:44<04:17,  2.71s/it] 53%|█████▎    | 106/200 [04:46<04:14,  2.71s/it] 54%|█████▎    | 107/200 [04:49<04:11,  2.71s/it] 54%|█████▍    | 108/200 [04:52<04:08,  2.71s/it] 55%|█████▍    | 109/200 [04:54<04:06,  2.71s/it] 55%|█████▌    | 110/200 [04:57<04:03,  2.70s/it] 56%|█████▌    | 111/200 [05:00<04:00,  2.71s/it] 56%|█████▌    | 112/200 [05:02<03:58,  2.71s/it] 56%|█████▋    | 113/200 [05:05<03:55,  2.71s/it] 57%|█████▋    | 114/200 [05:08<03:52,  2.71s/it] 57%|█████▊    | 115/200 [05:11<03:50,  2.71s/it] 58%|█████▊    | 116/200 [05:13<03:47,  2.71s/it] 58%|█████▊    | 117/200 [05:16<03:44,  2.71s/it] 59%|█████▉    | 118/200 [05:19<03:41,  2.71s/it] 60%|█████▉    | 119/200 [05:21<03:39,  2.71s/it] 60%|██████    | 120/200 [05:24<03:36,  2.71s/it] 60%|██████    | 121/200 [05:27<03:33,  2.70s/it] 61%|██████    | 122/200 [05:30<03:30,  2.70s/it] 62%|██████▏   | 123/200 [05:32<03:28,  2.70s/it] 62%|██████▏   | 124/200 [05:35<03:25,  2.70s/it] 62%|██████▎   | 125/200 [05:38<03:22,  2.70s/it] 63%|██████▎   | 126/200 [05:40<03:19,  2.70s/it] 64%|██████▎   | 127/200 [05:43<03:17,  2.70s/it] 64%|██████▍   | 128/200 [05:46<03:14,  2.70s/it] 64%|██████▍   | 129/200 [05:48<03:11,  2.70s/it] 65%|██████▌   | 130/200 [05:51<03:09,  2.70s/it] 66%|██████▌   | 131/200 [05:54<03:06,  2.70s/it] 66%|██████▌   | 132/200 [05:57<03:03,  2.70s/it] 66%|██████▋   | 133/200 [05:59<03:01,  2.70s/it] 67%|██████▋   | 134/200 [06:02<02:59,  2.73s/it] 68%|██████▊   | 135/200 [06:05<02:57,  2.73s/it] 68%|██████▊   | 136/200 [06:07<02:54,  2.72s/it] 68%|██████▊   | 137/200 [06:10<02:51,  2.72s/it] 69%|██████▉   | 138/200 [06:13<02:48,  2.71s/it] 70%|██████▉   | 139/200 [06:16<02:45,  2.71s/it] 70%|███████   | 140/200 [06:18<02:42,  2.71s/it] 70%|███████   | 141/200 [06:21<02:39,  2.71s/it] 71%|███████   | 142/200 [06:24<02:36,  2.71s/it] 72%|███████▏  | 143/200 [06:26<02:34,  2.70s/it] 72%|███████▏  | 144/200 [06:29<02:31,  2.70s/it] 72%|███████▎  | 145/200 [06:32<02:28,  2.70s/it] 73%|███████▎  | 146/200 [06:34<02:25,  2.70s/it] 74%|███████▎  | 147/200 [06:37<02:23,  2.70s/it] 74%|███████▍  | 148/200 [06:40<02:20,  2.70s/it] 74%|███████▍  | 149/200 [06:43<02:17,  2.70s/it] 75%|███████▌  | 150/200 [06:45<02:15,  2.70s/it] 76%|███████▌  | 151/200 [06:48<02:12,  2.70s/it] 76%|███████▌  | 152/200 [06:51<02:09,  2.70s/it] 76%|███████▋  | 153/200 [06:53<02:06,  2.70s/it] 77%|███████▋  | 154/200 [06:56<02:04,  2.70s/it] 78%|███████▊  | 155/200 [06:59<02:01,  2.70s/it] 78%|███████▊  | 156/200 [07:01<01:58,  2.70s/it] 78%|███████▊  | 157/200 [07:04<01:56,  2.70s/it] 79%|███████▉  | 158/200 [07:07<01:53,  2.70s/it] 80%|███████▉  | 159/200 [07:10<01:50,  2.70s/it] 80%|████████  | 160/200 [07:12<01:47,  2.70s/it] 80%|████████  | 161/200 [07:15<01:45,  2.70s/it] 81%|████████  | 162/200 [07:18<01:42,  2.70s/it] 82%|████████▏ | 163/200 [07:20<01:39,  2.70s/it] 82%|████████▏ | 164/200 [07:23<01:37,  2.70s/it] 82%|████████▎ | 165/200 [07:26<01:34,  2.69s/it] 83%|████████▎ | 166/200 [07:28<01:31,  2.69s/it] 84%|████████▎ | 167/200 [07:31<01:28,  2.69s/it] 84%|████████▍ | 168/200 [07:34<01:26,  2.70s/it] 84%|████████▍ | 169/200 [07:37<01:23,  2.70s/it] 85%|████████▌ | 170/200 [07:39<01:20,  2.70s/it] 86%|████████▌ | 171/200 [07:42<01:18,  2.69s/it] 86%|████████▌ | 172/200 [07:45<01:15,  2.69s/it] 86%|████████▋ | 173/200 [07:47<01:12,  2.69s/it] 87%|████████▋ | 174/200 [07:50<01:09,  2.69s/it] 88%|████████▊ | 175/200 [07:53<01:07,  2.70s/it] 88%|████████▊ | 176/200 [07:55<01:04,  2.70s/it] 88%|████████▊ | 177/200 [07:58<01:02,  2.70s/it] 89%|████████▉ | 178/200 [08:01<00:59,  2.70s/it] 90%|████████▉ | 179/200 [08:04<00:56,  2.70s/it] 90%|█████████ | 180/200 [08:06<00:54,  2.70s/it] 90%|█████████ | 181/200 [08:09<00:51,  2.70s/it] 91%|█████████ | 182/200 [08:12<00:48,  2.70s/it] 92%|█████████▏| 183/200 [08:14<00:45,  2.70s/it] 92%|█████████▏| 184/200 [08:17<00:43,  2.70s/it] 92%|█████████▎| 185/200 [08:20<00:40,  2.70s/it] 93%|█████████▎| 186/200 [08:22<00:37,  2.70s/it] 94%|█████████▎| 187/200 [08:25<00:35,  2.70s/it] 94%|█████████▍| 188/200 [08:28<00:32,  2.70s/it] 94%|█████████▍| 189/200 [08:31<00:29,  2.70s/it] 95%|█████████▌| 190/200 [08:33<00:27,  2.70s/it] 96%|█████████▌| 191/200 [08:36<00:24,  2.70s/it] 96%|█████████▌| 192/200 [08:39<00:21,  2.70s/it] 96%|█████████▋| 193/200 [08:41<00:18,  2.70s/it] 97%|█████████▋| 194/200 [08:44<00:16,  2.70s/it] 98%|█████████▊| 195/200 [08:47<00:13,  2.71s/it] 98%|█████████▊| 196/200 [08:49<00:10,  2.71s/it] 98%|█████████▊| 197/200 [08:52<00:08,  2.70s/it] 99%|█████████▉| 198/200 [08:55<00:05,  2.70s/it]100%|█████████▉| 199/200 [08:58<00:02,  2.70s/it]100%|██████████| 200/200 [09:00<00:00,  2.67s/it]***** Running Evaluation *****
  Num examples = 800
  Batch size = 32

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|▊         | 2/25 [00:00<00:05,  4.41it/s][A
 12%|█▏        | 3/25 [00:00<00:07,  3.12it/s][A
 16%|█▌        | 4/25 [00:01<00:07,  2.70it/s][A
 20%|██        | 5/25 [00:01<00:07,  2.51it/s][A
 24%|██▍       | 6/25 [00:02<00:07,  2.40it/s][A
 28%|██▊       | 7/25 [00:02<00:07,  2.33it/s][A
 32%|███▏      | 8/25 [00:03<00:07,  2.29it/s][A
 36%|███▌      | 9/25 [00:03<00:07,  2.26it/s][A
 40%|████      | 10/25 [00:04<00:06,  2.24it/s][A
 44%|████▍     | 11/25 [00:04<00:06,  2.23it/s][A
 48%|████▊     | 12/25 [00:04<00:05,  2.22it/s][A
 52%|█████▏    | 13/25 [00:05<00:05,  2.22it/s][A
 56%|█████▌    | 14/25 [00:05<00:04,  2.21it/s][A
 60%|██████    | 15/25 [00:06<00:04,  2.21it/s][A
 64%|██████▍   | 16/25 [00:06<00:04,  2.21it/s][A
 68%|██████▊   | 17/25 [00:07<00:03,  2.20it/s][A
 72%|███████▏  | 18/25 [00:07<00:03,  2.20it/s][A
 76%|███████▌  | 19/25 [00:08<00:02,  2.20it/s][A
 80%|████████  | 20/25 [00:08<00:02,  2.20it/s][A
 84%|████████▍ | 21/25 [00:09<00:01,  2.20it/s][A
 88%|████████▊ | 22/25 [00:09<00:01,  2.20it/s][A
 92%|█████████▏| 23/25 [00:09<00:00,  2.20it/s][A
 96%|█████████▌| 24/25 [00:10<00:00,  2.20it/s][A
100%|██████████| 25/25 [00:10<00:00,  2.20it/s][A                                                 
                                               [A100%|██████████| 200/200 [09:13<00:00,  2.67s/it]
100%|██████████| 25/25 [00:11<00:00,  2.20it/s][A
                                               [A

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 200/200 [09:13<00:00,  2.67s/it]100%|██████████| 200/200 [09:13<00:00,  2.77s/it]
/projects/assigned/2122_ling573_elibales/repo/src/fine-tune.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  item = {key: torch.tensor(val[index]) for key, val in self.encodings.items()}
/projects/assigned/2122_ling573_elibales/repo/src/fine-tune.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  item = {key: torch.tensor(val[index]) for key, val in self.encodings.items()}
Configuration saved in src/models/roberta-fine-tuned-preproc/config.json
Model weights saved in src/models/roberta-fine-tuned-preproc/pytorch_model.bin
