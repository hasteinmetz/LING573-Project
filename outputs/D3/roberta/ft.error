Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
***** Running training *****
  Num examples = 6399
  Num Epochs = 1
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 200
  0%|          | 0/200 [00:00<?, ?it/s]/home2/hsteinm/573/repo/src/fine-tune.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  item = {key: torch.tensor(val[index]) for key, val in self.encodings.items()}
  0%|          | 1/200 [00:02<09:20,  2.82s/it]  1%|          | 2/200 [00:05<08:56,  2.71s/it]  2%|▏         | 3/200 [00:08<08:48,  2.68s/it]  2%|▏         | 4/200 [00:10<08:43,  2.67s/it]  2%|▎         | 5/200 [00:13<08:39,  2.66s/it]  3%|▎         | 6/200 [00:16<08:35,  2.66s/it]  4%|▎         | 7/200 [00:18<08:33,  2.66s/it]  4%|▍         | 8/200 [00:21<08:30,  2.66s/it]  4%|▍         | 9/200 [00:24<08:26,  2.65s/it]  5%|▌         | 10/200 [00:26<08:23,  2.65s/it]  6%|▌         | 11/200 [00:29<08:20,  2.65s/it]  6%|▌         | 12/200 [00:31<08:17,  2.65s/it]  6%|▋         | 13/200 [00:34<08:15,  2.65s/it]  7%|▋         | 14/200 [00:37<08:13,  2.65s/it]  8%|▊         | 15/200 [00:39<08:11,  2.66s/it]  8%|▊         | 16/200 [00:42<08:08,  2.66s/it]  8%|▊         | 17/200 [00:45<08:05,  2.65s/it]  9%|▉         | 18/200 [00:47<08:03,  2.66s/it] 10%|▉         | 19/200 [00:50<08:00,  2.66s/it] 10%|█         | 20/200 [00:53<07:57,  2.65s/it] 10%|█         | 21/200 [00:55<07:55,  2.65s/it] 11%|█         | 22/200 [00:58<07:52,  2.65s/it] 12%|█▏        | 23/200 [01:01<07:49,  2.65s/it] 12%|█▏        | 24/200 [01:03<07:48,  2.66s/it] 12%|█▎        | 25/200 [01:06<07:46,  2.66s/it] 13%|█▎        | 26/200 [01:09<07:45,  2.67s/it] 14%|█▎        | 27/200 [01:11<07:43,  2.68s/it] 14%|█▍        | 28/200 [01:14<07:42,  2.69s/it] 14%|█▍        | 29/200 [01:17<07:37,  2.68s/it] 15%|█▌        | 30/200 [01:19<07:34,  2.67s/it] 16%|█▌        | 31/200 [01:22<07:32,  2.68s/it] 16%|█▌        | 32/200 [01:25<07:28,  2.67s/it] 16%|█▋        | 33/200 [01:28<07:54,  2.84s/it] 17%|█▋        | 34/200 [01:31<07:42,  2.79s/it] 18%|█▊        | 35/200 [01:33<07:32,  2.74s/it] 18%|█▊        | 36/200 [01:36<07:25,  2.71s/it] 18%|█▊        | 37/200 [01:39<07:19,  2.70s/it] 19%|█▉        | 38/200 [01:41<07:14,  2.68s/it] 20%|█▉        | 39/200 [01:44<07:09,  2.67s/it] 20%|██        | 40/200 [01:47<07:05,  2.66s/it] 20%|██        | 41/200 [01:49<07:02,  2.66s/it] 21%|██        | 42/200 [01:52<06:59,  2.65s/it] 22%|██▏       | 43/200 [01:54<06:56,  2.65s/it] 22%|██▏       | 44/200 [01:57<06:53,  2.65s/it] 22%|██▎       | 45/200 [02:00<06:50,  2.65s/it] 23%|██▎       | 46/200 [02:02<06:47,  2.65s/it] 24%|██▎       | 47/200 [02:05<06:45,  2.65s/it] 24%|██▍       | 48/200 [02:08<06:42,  2.65s/it] 24%|██▍       | 49/200 [02:10<06:40,  2.65s/it] 25%|██▌       | 50/200 [02:13<06:37,  2.65s/it] 26%|██▌       | 51/200 [02:16<06:35,  2.65s/it] 26%|██▌       | 52/200 [02:18<06:32,  2.65s/it] 26%|██▋       | 53/200 [02:21<06:29,  2.65s/it] 27%|██▋       | 54/200 [02:24<06:26,  2.65s/it] 28%|██▊       | 55/200 [02:26<06:24,  2.65s/it] 28%|██▊       | 56/200 [02:29<06:22,  2.65s/it] 28%|██▊       | 57/200 [02:32<06:19,  2.65s/it] 29%|██▉       | 58/200 [02:34<06:16,  2.65s/it] 30%|██▉       | 59/200 [02:37<06:14,  2.65s/it] 30%|███       | 60/200 [02:40<06:11,  2.65s/it] 30%|███       | 61/200 [02:42<06:08,  2.65s/it] 31%|███       | 62/200 [02:45<06:05,  2.65s/it] 32%|███▏      | 63/200 [02:47<06:02,  2.65s/it] 32%|███▏      | 64/200 [02:50<06:00,  2.65s/it] 32%|███▎      | 65/200 [02:53<05:57,  2.65s/it] 33%|███▎      | 66/200 [02:55<05:55,  2.65s/it] 34%|███▎      | 67/200 [02:58<05:52,  2.65s/it] 34%|███▍      | 68/200 [03:01<05:50,  2.65s/it] 34%|███▍      | 69/200 [03:03<05:47,  2.65s/it] 35%|███▌      | 70/200 [03:06<05:44,  2.65s/it]