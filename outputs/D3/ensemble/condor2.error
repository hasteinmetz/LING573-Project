Using the GPU:Tesla M10
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
	(epoch 1, fold 1, samples 320) FClassifier Loss: 0.7222581338137388 Transformer Loss: 0.7245736718177795
	(epoch 1, fold 1, samples 640) FClassifier Loss: 0.5757635943591595 Transformer Loss: 0.5033048391342163
	(epoch 1, fold 1, samples 960) FClassifier Loss: 0.5769076822325587 Transformer Loss: 0.1791958510875702
	(epoch 1, fold 1, samples 1280) FClassifier Loss: 0.5758484555408359 Transformer Loss: 0.3633120656013489
	(epoch 1, fold 1, samples 1600) FClassifier Loss: 0.4956108946353197 Transformer Loss: 0.2457255721092224
	(epoch 1, fold 1, samples 1920) FClassifier Loss: 0.5444805286824703 Transformer Loss: 0.21792234480381012
	(epoch 1, fold 1, samples 2240) FClassifier Loss: 0.5552111230790615 Transformer Loss: 0.25423476099967957
	(epoch 1, fold 1, samples 2560) FClassifier Loss: 0.5630271164700389 Transformer Loss: 0.21389929950237274
	(epoch 1, fold 1, samples 2880) FClassifier Loss: 0.49645158275961876 Transformer Loss: 0.09751380980014801
	(epoch 1, fold 1, samples 3200) FClassifier Loss: 0.5184402372688055 Transformer Loss: 0.03980952501296997
	(epoch 1, fold 1, samples 3520) FClassifier Loss: 0.6421901853755116 Transformer Loss: 0.2169264256954193
	(epoch 1, fold 1, samples 3840) FClassifier Loss: 0.5527104157954454 Transformer Loss: 0.14669042825698853
	(epoch 1, fold 1, samples 4160) FClassifier Loss: 0.5925867604091763 Transformer Loss: 0.24209122359752655
(epoch 1, fold 1, samples 320) Regression Accuracy: 0.9375, Loss: 0.3893621563911438
(epoch 1, fold 1, samples 640) Regression Accuracy: 1.0, Loss: 0.2727208435535431
(epoch 1, fold 1, samples 960) Regression Accuracy: 0.9375, Loss: 0.24012774229049683
(epoch 1, fold 1, samples 1280) Regression Accuracy: 0.96875, Loss: 0.2772393226623535
(epoch 1, fold 1, samples 1600) Regression Accuracy: 0.96875, Loss: 0.2111809104681015
(epoch 1, fold 1, samples 1920) Regression Accuracy: 1.0, Loss: 0.19156864285469055
	(epoch 1, fold 2, samples 320) FClassifier Loss: 0.4863293981179595 Transformer Loss: 0.40807044506073
	(epoch 1, fold 2, samples 640) FClassifier Loss: 0.49154868721961975 Transformer Loss: 0.15252052247524261
	(epoch 1, fold 2, samples 960) FClassifier Loss: 0.45820717234164476 Transformer Loss: 0.12265533208847046
	(epoch 1, fold 2, samples 1280) FClassifier Loss: 0.4986351318657398 Transformer Loss: 0.3555953800678253
	(epoch 1, fold 2, samples 1600) FClassifier Loss: 0.49103226605802774 Transformer Loss: 0.17670416831970215
	(epoch 1, fold 2, samples 1920) FClassifier Loss: 0.5623360937461257 Transformer Loss: 0.1874620020389557
	(epoch 1, fold 2, samples 2240) FClassifier Loss: 0.5094302985817194 Transformer Loss: 0.20285823941230774
	(epoch 1, fold 2, samples 2560) FClassifier Loss: 0.4868183881044388 Transformer Loss: 0.1136573776602745
	(epoch 1, fold 2, samples 2880) FClassifier Loss: 0.4271859908476472 Transformer Loss: 0.08884989470243454
	(epoch 1, fold 2, samples 3200) FClassifier Loss: 0.40384257957339287 Transformer Loss: 0.02490074560046196
	(epoch 1, fold 2, samples 3520) FClassifier Loss: 0.5149302333593369 Transformer Loss: 0.06675364822149277
	(epoch 1, fold 2, samples 3840) FClassifier Loss: 0.5021458957344294 Transformer Loss: 0.048617810010910034
	(epoch 1, fold 2, samples 4160) FClassifier Loss: 0.5460860412567854 Transformer Loss: 0.023154154419898987
(epoch 1, fold 2, samples 320) Regression Accuracy: 0.96875, Loss: 0.11468462646007538
(epoch 1, fold 2, samples 640) Regression Accuracy: 0.96875, Loss: 0.07719239592552185
(epoch 1, fold 2, samples 960) Regression Accuracy: 1.0, Loss: 0.057841502130031586
(epoch 1, fold 2, samples 1280) Regression Accuracy: 0.96875, Loss: 0.11092961579561234
(epoch 1, fold 2, samples 1600) Regression Accuracy: 0.96875, Loss: 0.0870407447218895
(epoch 1, fold 2, samples 1920) Regression Accuracy: 0.96875, Loss: 0.1017274484038353
	(epoch 1, fold 3, samples 320) FClassifier Loss: 0.39950969256460667 Transformer Loss: 0.0912247747182846
	(epoch 1, fold 3, samples 640) FClassifier Loss: 0.3470285823568702 Transformer Loss: 0.03114008903503418
	(epoch 1, fold 3, samples 960) FClassifier Loss: 0.4249599976465106 Transformer Loss: 0.029293054714798927
	(epoch 1, fold 3, samples 1280) FClassifier Loss: 0.39921451918780804 Transformer Loss: 0.1336289942264557
	(epoch 1, fold 3, samples 1600) FClassifier Loss: 0.38769306894391775 Transformer Loss: 0.02609061449766159
	(epoch 1, fold 3, samples 1920) FClassifier Loss: 0.5036928243935108 Transformer Loss: 0.03891318663954735
	(epoch 1, fold 3, samples 2240) FClassifier Loss: 0.4987758118659258 Transformer Loss: 0.42151448130607605
	(epoch 1, fold 3, samples 2560) FClassifier Loss: 0.5215409835800529 Transformer Loss: 0.24421650171279907
	(epoch 1, fold 3, samples 2880) FClassifier Loss: 0.37435372546315193 Transformer Loss: 0.06792066991329193
	(epoch 1, fold 3, samples 3200) FClassifier Loss: 0.4236095864325762 Transformer Loss: 0.02725449949502945
	(epoch 1, fold 3, samples 3520) FClassifier Loss: 0.4360600784420967 Transformer Loss: 0.029471496120095253
	(epoch 1, fold 3, samples 3840) FClassifier Loss: 0.34099231846630573 Transformer Loss: 0.060335833579301834
	(epoch 1, fold 3, samples 4160) FClassifier Loss: 0.39938957430422306 Transformer Loss: 0.015678390860557556
(epoch 1, fold 3, samples 320) Regression Accuracy: 0.96875, Loss: 0.093601755797863
(epoch 1, fold 3, samples 640) Regression Accuracy: 0.96875, Loss: 0.13083285093307495
(epoch 1, fold 3, samples 960) Regression Accuracy: 1.0, Loss: 0.06414256244897842
(epoch 1, fold 3, samples 1280) Regression Accuracy: 1.0, Loss: 0.062318816781044006
(epoch 1, fold 3, samples 1600) Regression Accuracy: 1.0, Loss: 0.0360184982419014
(epoch 1, fold 3, samples 1920) Regression Accuracy: 1.0, Loss: 0.0438833013176918

real	29m30.153s
user	23m9.973s
sys	5m22.497s
