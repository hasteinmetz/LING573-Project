Using cuda device
<<<<<<< HEAD
loading training and development data...
initializing ensemble architecture
f1:
	 {'f1': 0.9500509683995922}
accuracy:
	 {'accuracy': 0.93875}

=======
Using the GPU:Tesla M10
loading training and development data...
initializing ensemble architecture
training ensemble model...
	splitting data in k-folds to cross-validate...
<<<<<<< HEAD
{'input_ids': tensor([[    0,   565, 22722,  ...,     1,     1,     1],
        [    0,   250,   313,  ...,     1,     1,     1],
        [    0,  6179,   171,  ...,     1,     1,     1],
        ...,
        [    0, 13368, 24665,  ...,     1,     1,     1],
        [    0,   243,    18,  ...,     1,     1,     1],
        [    0,   574,  2990,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]])}
>>>>>>> 731cd07 (cleaning up messy merge)
=======
(train-fold 0) training mlp classifier...
MLP accuracy: 0.3710618436406068
(train-fold 0) training roberta...
>>>>>>> df05928 (small bug fix)
