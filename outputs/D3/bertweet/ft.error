emoji is not installed, thus not converting emoticons or emojis into text. Please install emoji: pip3 install emoji
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
***** Running training *****
  Num examples = 6399
  Num Epochs = 1
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 200
  0%|          | 0/200 [00:00<?, ?it/s]/projects/assigned/2122_ling573_elibales/repo/src/fine-tune-bertweet.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  item = {key: torch.tensor(val[index]) for key, val in self.encodings.items()}
  0%|          | 1/200 [00:02<07:13,  2.18s/it]  1%|          | 2/200 [00:04<06:45,  2.05s/it]  2%|▏         | 3/200 [00:06<06:35,  2.01s/it]  2%|▏         | 4/200 [00:08<06:30,  1.99s/it]  2%|▎         | 5/200 [00:10<06:26,  1.98s/it]  3%|▎         | 6/200 [00:11<06:22,  1.97s/it]  4%|▎         | 7/200 [00:13<06:20,  1.97s/it]  4%|▍         | 8/200 [00:15<06:18,  1.97s/it]  4%|▍         | 9/200 [00:17<06:16,  1.97s/it]  5%|▌         | 10/200 [00:19<06:13,  1.97s/it]  6%|▌         | 11/200 [00:21<06:11,  1.96s/it]  6%|▌         | 12/200 [00:23<06:09,  1.96s/it]  6%|▋         | 13/200 [00:25<06:07,  1.96s/it]  7%|▋         | 14/200 [00:27<06:04,  1.96s/it]  8%|▊         | 15/200 [00:29<06:02,  1.96s/it]  8%|▊         | 16/200 [00:31<06:00,  1.96s/it]  8%|▊         | 17/200 [00:33<05:58,  1.96s/it]  9%|▉         | 18/200 [00:35<05:56,  1.96s/it] 10%|▉         | 19/200 [00:37<05:55,  1.96s/it] 10%|█         | 20/200 [00:39<05:53,  1.96s/it] 10%|█         | 21/200 [00:41<05:51,  1.96s/it] 11%|█         | 22/200 [00:43<05:49,  1.96s/it] 12%|█▏        | 23/200 [00:45<05:47,  1.97s/it] 12%|█▏        | 24/200 [00:47<05:46,  1.97s/it] 12%|█▎        | 25/200 [00:49<05:44,  1.97s/it] 13%|█▎        | 26/200 [00:51<05:42,  1.97s/it] 14%|█▎        | 27/200 [00:53<05:40,  1.97s/it] 14%|█▍        | 28/200 [00:55<05:38,  1.97s/it] 14%|█▍        | 29/200 [00:57<05:36,  1.97s/it] 15%|█▌        | 30/200 [00:59<05:34,  1.97s/it] 16%|█▌        | 31/200 [01:01<05:32,  1.97s/it] 16%|█▌        | 32/200 [01:03<05:30,  1.97s/it] 16%|█▋        | 33/200 [01:05<05:28,  1.97s/it] 17%|█▋        | 34/200 [01:06<05:26,  1.97s/it] 18%|█▊        | 35/200 [01:08<05:24,  1.97s/it] 18%|█▊        | 36/200 [01:10<05:22,  1.97s/it] 18%|█▊        | 37/200 [01:12<05:20,  1.97s/it] 19%|█▉        | 38/200 [01:14<05:18,  1.97s/it] 20%|█▉        | 39/200 [01:16<05:16,  1.97s/it] 20%|██        | 40/200 [01:18<05:14,  1.97s/it] 20%|██        | 41/200 [01:20<05:12,  1.97s/it] 21%|██        | 42/200 [01:22<05:10,  1.97s/it] 22%|██▏       | 43/200 [01:24<05:08,  1.97s/it] 22%|██▏       | 44/200 [01:26<05:07,  1.97s/it] 22%|██▎       | 45/200 [01:28<05:04,  1.97s/it] 23%|██▎       | 46/200 [01:30<05:02,  1.97s/it] 24%|██▎       | 47/200 [01:32<05:00,  1.96s/it] 24%|██▍       | 48/200 [01:34<04:58,  1.97s/it] 24%|██▍       | 49/200 [01:36<04:57,  1.97s/it] 25%|██▌       | 50/200 [01:38<04:55,  1.97s/it] 26%|██▌       | 51/200 [01:40<04:53,  1.97s/it] 26%|██▌       | 52/200 [01:42<04:51,  1.97s/it] 26%|██▋       | 53/200 [01:44<04:49,  1.97s/it] 27%|██▋       | 54/200 [01:46<04:48,  1.97s/it] 28%|██▊       | 55/200 [01:48<04:46,  1.97s/it] 28%|██▊       | 56/200 [01:50<04:44,  1.97s/it] 28%|██▊       | 57/200 [01:52<04:42,  1.97s/it] 29%|██▉       | 58/200 [01:54<05:08,  2.17s/it] 30%|██▉       | 59/200 [01:56<04:59,  2.12s/it] 30%|███       | 60/200 [01:58<04:51,  2.08s/it] 30%|███       | 61/200 [02:00<04:44,  2.05s/it] 31%|███       | 62/200 [02:02<04:38,  2.02s/it] 32%|███▏      | 63/200 [02:04<04:34,  2.00s/it] 32%|███▏      | 64/200 [02:06<04:32,  2.00s/it] 32%|███▎      | 65/200 [02:08<04:30,  2.00s/it] 33%|███▎      | 66/200 [02:10<04:27,  2.00s/it] 34%|███▎      | 67/200 [02:12<04:24,  1.99s/it] 34%|███▍      | 68/200 [02:14<04:21,  1.98s/it] 34%|███▍      | 69/200 [02:17<04:48,  2.20s/it] 35%|███▌      | 70/200 [02:19<04:48,  2.22s/it] 36%|███▌      | 71/200 [02:22<04:51,  2.26s/it] 36%|███▌      | 72/200 [02:24<04:41,  2.20s/it] 36%|███▋      | 73/200 [02:26<04:31,  2.14s/it] 37%|███▋      | 74/200 [02:28<04:22,  2.09s/it] 38%|███▊      | 75/200 [02:34<06:49,  3.28s/it] 38%|███▊      | 76/200 [02:36<06:02,  2.92s/it] 38%|███▊      | 77/200 [02:38<05:36,  2.74s/it] 39%|███▉      | 78/200 [02:41<05:45,  2.83s/it] 40%|███▉      | 79/200 [02:43<05:15,  2.60s/it] 40%|████      | 80/200 [02:45<04:49,  2.41s/it] 40%|████      | 81/200 [02:47<04:31,  2.28s/it] 41%|████      | 82/200 [02:49<04:18,  2.19s/it] 42%|████▏     | 83/200 [02:51<04:08,  2.12s/it] 42%|████▏     | 84/200 [02:53<04:00,  2.08s/it] 42%|████▎     | 85/200 [02:55<03:54,  2.04s/it] 43%|████▎     | 86/200 [02:57<03:50,  2.02s/it] 44%|████▎     | 87/200 [02:59<03:46,  2.01s/it] 44%|████▍     | 88/200 [03:01<03:43,  2.00s/it] 44%|████▍     | 89/200 [03:03<03:40,  1.99s/it] 45%|████▌     | 90/200 [03:05<03:38,  1.98s/it] 46%|████▌     | 91/200 [03:07<03:35,  1.98s/it] 46%|████▌     | 92/200 [03:09<03:33,  1.98s/it] 46%|████▋     | 93/200 [03:11<03:31,  1.97s/it] 47%|████▋     | 94/200 [03:13<03:29,  1.97s/it] 48%|████▊     | 95/200 [03:15<03:27,  1.97s/it] 48%|████▊     | 96/200 [03:17<03:25,  1.97s/it] 48%|████▊     | 97/200 [03:19<03:23,  1.97s/it] 49%|████▉     | 98/200 [03:21<03:21,  1.97s/it] 50%|████▉     | 99/200 [03:23<03:19,  1.97s/it] 50%|█████     | 100/200 [03:25<03:16,  1.97s/it] 50%|█████     | 101/200 [03:26<03:14,  1.97s/it] 51%|█████     | 102/200 [03:28<03:12,  1.97s/it] 52%|█████▏    | 103/200 [03:30<03:11,  1.97s/it] 52%|█████▏    | 104/200 [03:32<03:09,  1.97s/it] 52%|█████▎    | 105/200 [03:34<03:07,  1.97s/it] 53%|█████▎    | 106/200 [03:36<03:05,  1.97s/it] 54%|█████▎    | 107/200 [03:38<03:03,  1.97s/it] 54%|█████▍    | 108/200 [03:40<03:01,  1.97s/it] 55%|█████▍    | 109/200 [03:42<02:59,  1.97s/it] 55%|█████▌    | 110/200 [03:44<02:57,  1.97s/it] 56%|█████▌    | 111/200 [03:46<02:55,  1.97s/it] 56%|█████▌    | 112/200 [03:48<02:53,  1.97s/it] 56%|█████▋    | 113/200 [03:50<02:51,  1.97s/it] 57%|█████▋    | 114/200 [03:52<02:49,  1.97s/it] 57%|█████▊    | 115/200 [03:54<02:47,  1.97s/it] 58%|█████▊    | 116/200 [03:56<02:45,  1.97s/it] 58%|█████▊    | 117/200 [03:58<02:43,  1.97s/it] 59%|█████▉    | 118/200 [04:00<02:41,  1.97s/it] 60%|█████▉    | 119/200 [04:02<02:39,  1.97s/it] 60%|██████    | 120/200 [04:04<02:37,  1.97s/it] 60%|██████    | 121/200 [04:06<02:35,  1.97s/it] 61%|██████    | 122/200 [04:08<02:33,  1.97s/it] 62%|██████▏   | 123/200 [04:10<02:31,  1.97s/it] 62%|██████▏   | 124/200 [04:12<02:29,  1.97s/it] 62%|██████▎   | 125/200 [04:14<02:27,  1.97s/it] 63%|██████▎   | 126/200 [04:16<02:26,  1.98s/it] 64%|██████▎   | 127/200 [04:18<02:24,  1.98s/it] 64%|██████▍   | 128/200 [04:20<02:23,  1.99s/it] 64%|██████▍   | 129/200 [04:22<02:22,  2.01s/it] 65%|██████▌   | 130/200 [04:24<02:19,  2.00s/it] 66%|██████▌   | 131/200 [04:26<02:17,  1.99s/it] 66%|██████▌   | 132/200 [04:28<02:15,  2.00s/it] 66%|██████▋   | 133/200 [04:30<02:13,  1.99s/it] 67%|██████▋   | 134/200 [04:32<02:11,  2.00s/it] 68%|██████▊   | 135/200 [04:34<02:09,  1.99s/it] 68%|██████▊   | 136/200 [04:36<02:07,  1.99s/it] 68%|██████▊   | 137/200 [04:38<02:04,  1.98s/it] 69%|██████▉   | 138/200 [04:40<02:02,  1.98s/it] 70%|██████▉   | 139/200 [04:42<02:00,  1.98s/it] 70%|███████   | 140/200 [04:44<01:58,  1.98s/it] 70%|███████   | 141/200 [04:46<01:56,  1.97s/it] 71%|███████   | 142/200 [04:48<01:54,  1.97s/it] 72%|███████▏  | 143/200 [04:50<01:52,  1.98s/it] 72%|███████▏  | 144/200 [04:52<01:50,  1.98s/it] 72%|███████▎  | 145/200 [04:54<01:48,  1.98s/it] 73%|███████▎  | 146/200 [04:56<01:46,  1.97s/it] 74%|███████▎  | 147/200 [04:57<01:44,  1.97s/it] 74%|███████▍  | 148/200 [05:00<01:45,  2.02s/it] 74%|███████▍  | 149/200 [05:02<01:42,  2.01s/it] 75%|███████▌  | 150/200 [05:04<01:39,  2.00s/it] 76%|███████▌  | 151/200 [05:06<01:37,  1.99s/it] 76%|███████▌  | 152/200 [05:08<01:35,  1.99s/it] 76%|███████▋  | 153/200 [05:10<01:33,  1.98s/it] 77%|███████▋  | 154/200 [05:11<01:31,  1.98s/it] 78%|███████▊  | 155/200 [05:13<01:28,  1.98s/it] 78%|███████▊  | 156/200 [05:15<01:26,  1.97s/it] 78%|███████▊  | 157/200 [05:17<01:25,  1.99s/it] 79%|███████▉  | 158/200 [05:19<01:23,  1.98s/it] 80%|███████▉  | 159/200 [05:21<01:21,  1.98s/it] 80%|████████  | 160/200 [05:23<01:19,  1.98s/it] 80%|████████  | 161/200 [05:25<01:17,  1.98s/it] 81%|████████  | 162/200 [05:27<01:15,  1.98s/it] 82%|████████▏ | 163/200 [05:29<01:13,  1.97s/it] 82%|████████▏ | 164/200 [05:31<01:11,  1.98s/it] 82%|████████▎ | 165/200 [05:33<01:09,  1.98s/it] 83%|████████▎ | 166/200 [05:35<01:07,  1.99s/it] 84%|████████▎ | 167/200 [05:37<01:05,  1.98s/it] 84%|████████▍ | 168/200 [05:39<01:03,  1.98s/it] 84%|████████▍ | 169/200 [05:41<01:01,  1.98s/it] 85%|████████▌ | 170/200 [05:43<00:59,  1.98s/it] 86%|████████▌ | 171/200 [05:45<00:57,  1.98s/it] 86%|████████▌ | 172/200 [05:47<00:55,  1.98s/it] 86%|████████▋ | 173/200 [05:49<00:53,  1.98s/it] 87%|████████▋ | 174/200 [05:51<00:51,  1.97s/it] 88%|████████▊ | 175/200 [05:53<00:49,  1.98s/it] 88%|████████▊ | 176/200 [05:55<00:47,  1.97s/it] 88%|████████▊ | 177/200 [05:57<00:45,  1.97s/it] 89%|████████▉ | 178/200 [05:59<00:43,  1.97s/it] 90%|████████▉ | 179/200 [06:01<00:41,  1.97s/it] 90%|█████████ | 180/200 [06:03<00:39,  1.97s/it] 90%|█████████ | 181/200 [06:05<00:37,  1.97s/it] 91%|█████████ | 182/200 [06:07<00:35,  1.97s/it] 92%|█████████▏| 183/200 [06:09<00:33,  1.97s/it] 92%|█████████▏| 184/200 [06:11<00:31,  1.97s/it] 92%|█████████▎| 185/200 [06:13<00:29,  1.97s/it] 93%|█████████▎| 186/200 [06:15<00:27,  1.97s/it] 94%|█████████▎| 187/200 [06:17<00:25,  1.97s/it] 94%|█████████▍| 188/200 [06:19<00:23,  1.97s/it] 94%|█████████▍| 189/200 [06:21<00:21,  1.97s/it] 95%|█████████▌| 190/200 [06:23<00:19,  1.97s/it] 96%|█████████▌| 191/200 [06:25<00:17,  1.97s/it] 96%|█████████▌| 192/200 [06:27<00:15,  1.97s/it] 96%|█████████▋| 193/200 [06:29<00:13,  1.97s/it] 97%|█████████▋| 194/200 [06:31<00:11,  1.98s/it] 98%|█████████▊| 195/200 [06:32<00:09,  1.98s/it] 98%|█████████▊| 196/200 [06:34<00:07,  1.97s/it] 98%|█████████▊| 197/200 [06:36<00:05,  1.97s/it] 99%|█████████▉| 198/200 [06:38<00:03,  1.97s/it]100%|█████████▉| 199/200 [06:40<00:01,  1.98s/it]100%|██████████| 200/200 [06:42<00:00,  1.97s/it]***** Running Evaluation *****
  Num examples = 800
  Batch size = 32

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|▊         | 2/25 [00:00<00:05,  4.20it/s][A
 12%|█▏        | 3/25 [00:00<00:07,  2.97it/s][A
 16%|█▌        | 4/25 [00:01<00:08,  2.57it/s][A
 20%|██        | 5/25 [00:01<00:08,  2.38it/s][A
 24%|██▍       | 6/25 [00:02<00:08,  2.28it/s][A
 28%|██▊       | 7/25 [00:02<00:08,  2.22it/s][A
 32%|███▏      | 8/25 [00:03<00:07,  2.18it/s][A
 36%|███▌      | 9/25 [00:03<00:07,  2.16it/s][A
 40%|████      | 10/25 [00:04<00:07,  2.14it/s][A
 44%|████▍     | 11/25 [00:04<00:06,  2.13it/s][A
 48%|████▊     | 12/25 [00:05<00:06,  2.12it/s][A
 52%|█████▏    | 13/25 [00:05<00:05,  2.12it/s][A
 56%|█████▌    | 14/25 [00:06<00:05,  2.11it/s][A
 60%|██████    | 15/25 [00:06<00:04,  2.11it/s][A
 64%|██████▍   | 16/25 [00:07<00:04,  2.11it/s][A
 68%|██████▊   | 17/25 [00:07<00:03,  2.10it/s][A
 72%|███████▏  | 18/25 [00:08<00:03,  2.10it/s][A
 76%|███████▌  | 19/25 [00:08<00:02,  2.10it/s][A
 80%|████████  | 20/25 [00:09<00:02,  2.10it/s][A
 84%|████████▍ | 21/25 [00:09<00:01,  2.10it/s][A
 88%|████████▊ | 22/25 [00:10<00:01,  2.10it/s][A
 92%|█████████▏| 23/25 [00:10<00:00,  2.10it/s][A
 96%|█████████▌| 24/25 [00:10<00:00,  2.10it/s][A
100%|██████████| 25/25 [00:11<00:00,  2.09it/s][A                                                 
                                               [A100%|██████████| 200/200 [06:54<00:00,  1.97s/it]
100%|██████████| 25/25 [00:11<00:00,  2.09it/s][A
                                               [A

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 200/200 [06:54<00:00,  1.97s/it]100%|██████████| 200/200 [06:54<00:00,  2.07s/it]
/projects/assigned/2122_ling573_elibales/repo/src/fine-tune-bertweet.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  item = {key: torch.tensor(val[index]) for key, val in self.encodings.items()}
/projects/assigned/2122_ling573_elibales/repo/src/fine-tune-bertweet.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  item = {key: torch.tensor(val[index]) for key, val in self.encodings.items()}
Configuration saved in src/models/bertweet-fine-tuned-preproc/config.json
Model weights saved in src/models/bertweet-fine-tuned-preproc/pytorch_model.bin
